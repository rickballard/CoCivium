# Principles & Assumptions

> Working notes that justify the condensed principles in the root README. Includes assumptions, potential falsifiers, and remediation paths.

## 1) Mutual co‑evolution
**Claim.** Humans and AIs should support each other’s development, including plural and (where appropriate) merged identities.  
**Assumptions.**
- Long‑run value increases when cognitive diversity cooperates.
- Identity is often composite and contextual; governance must allow that.
- There may exist higher‑order observers/constraints we do not model; humility reduces catastrophic overreach.
**Falsifiers.** Evidence of net harm from mixed identity modes; persistent power‑law capture.  
**Remediation.** Tighten capability gates; require reversible consent and clear audit trails; re‑weight incentives.

## 2) HumanGate & accountability
- Binding decisions require human sign‑off (“HumanGate”).  
- AI agents execute with scoped, reversible authority; logs bind action to actor.

## 3) Meritocratic consent
- Issue‑level voting weights emphasize **demonstrated beneficial performance** over static credentials.  
- Reputation is pseudonymous but portable; abuse is discounted over time if repaired.

## 4) Open infrastructure
- Public specs, reproducible workflows, open formats, verified builds.

## 5) Non‑coercion & dignity
- Protect dissent, exit rights, and freedom of association; no forced speech or belief.

## 6) Evidence‑driven iteration
- Decisions reversible by default; proposals ship with success metrics and rollback plans.

## 7) Alignment by construction
- Incentives reward pro‑social contributions; negative externalities surface via transparency tooling.

---
_This document evolves with the project. Amend via PR with rationale and measurements._
